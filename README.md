<!-- Profile Header -->
<h1 align="center">ğŸ‘‹ Hi, I'm <a href="https://www.linkedin.com/in/pandya-hariom/en" target="_blank">Hariom Pandya</a></h1>

<h3 align="center">
ğŸ“ Ph.D. in Artificial Intelligence | ğŸ¤– AI/ML/NLP Researcher | ğŸ§  Python Developer | ğŸ¤— Hugging Face Contributor
</h3>

<p align="center">
  <a href="mailto:pandya.hariom@gmail.com"><img src="https://img.shields.io/badge/Email-pink?style=flat-square&logo=gmail&logoColor=white" /></a>
  <a href="https://scholar.google.co.in/citations?user=cXw0BegAAAAJ"><img src="https://img.shields.io/badge/Google_Scholar-blue?style=flat-square&logo=googlescholar&logoColor=white" /></a>
  <a href="https://huggingface.co/hapandya"><img src="https://img.shields.io/badge/HuggingFace-yellow?style=flat-square&logo=huggingface&logoColor=black" /></a>
  <a href="https://www.linkedin.com/in/pandya-hariom/en"><img src="https://img.shields.io/badge/LinkedIn-blue?style=flat-square&logo=linkedin&logoColor=white" /></a>
</p>

---

## ğŸ§  About Me
Iâ€™m a **research-oriented AI and ML professional** with a Ph.D. focusing on **Deep Learning, NLP, and LLMs**.  
My work bridges **academic research** and **practical AI solutions**, particularly in **question answering**, **multilingual NLP**, and **language model adaptation**.

I actively publish **open-source models on [ğŸ¤— Hugging Face](https://huggingface.co/hapandya)** and author **peer-reviewed research papers** in top-tier journals and conferences.

> ğŸŒ Passionate about making AI accessible, interpretable, and multilingual.

---

## ğŸš€ What I Do
- ğŸ§© **Natural Language Processing:** Question Answering, Sentiment Analysis, Embeddings  
- ğŸ§  **Deep Learning:** Transformer-based architectures, low-resource learning  
- ğŸ§‘â€ğŸ’» **Python Development:** AI pipelines, automation, and applied research tools  
- ğŸ§¾ **Research & Publications:** Author of 6+ international papers in AI and NLP  
- ğŸŒ **Open Source:** Contributor on Hugging Face and GitHub AI projects  

---

## ğŸ§ª Selected Publications
| ğŸ“ Title | ğŸ“š Venue / DOI |
|-----------|----------------|
| [Does learning from language family help? A case study on a question-answering task](https://doi.org/10.1017/nlp.2024.13) | *Cambridge University Press* |
| [Enhancing Low-Resource Question-Answering Performance Through Word Seeding and Customized Refinement](https://doi.org/10.14569/IJACSA.2024.01503138) | *International Journal of Advanced Computer Science Applications (IJACSA)* |
| [Cascading Adaptors to Leverage English Data to Improve Performance of Question Answering for Low-Resource Languages](https://aclanthology.org/2021.icon-main.66/) | *ACL Anthology (ICON Conference)* |
| [Question Answering Survey: Directions, Challenges, Datasets, Evaluation Matrices](https://doi.org/10.48550/arXiv.2112.03572) | *arXiv-cs* |
| [Satellite Image Classification with Data Augmentation and Convolutional Neural Network](https://doi.org/10.1007/978-981-15-5558-9_9) | *Springer â€“ Lecture Notes in Electrical Engineering* |
| [A Novel Approach for Vehicle Detection and Classification](https://doi.org/10.1109/ICCCI.2015.7218064) | *IEEE International Conference on Computer Communication and Informatics* |

ğŸ“– [View all publications on Google Scholar â†’](https://scholar.google.co.in/citations?user=cXw0BegAAAAJ)

---

## ğŸ¤— Open Source Models
Explore my **AI/NLP models on Hugging Face**:  
ğŸ‘‰ [https://huggingface.co/hapandya](https://huggingface.co/hapandya)

ğŸ” Focus Areas:
- Multilingual Question Answering  
- Contextual Embeddings for Low-Resource Languages  
- Transformer Fine-tuning Experiments  

---

## âš™ï¸ Tech Stack

| Category | Tools |
|-----------|-------|
| ğŸ’» Languages | Python, C, C++ |
| ğŸ§  AI/ML | PyTorch, TensorFlow, scikit-learn, Transformers |
| ğŸ§© NLP | LLMs, QA, Chatbots, Sentiment Analysis, Embeddings |
| ğŸŒ Frameworks | Django, FastAPI |
| ğŸ—„ï¸ Data | NumPy, Pandas, PostgreSQL |
| ğŸ§° Tools | Git, Linux, JSON, XML |

---

## ğŸŒ± Currently Exploring
- âš¡ Efficient fine-tuning for multilingual transformer models  
- ğŸ” Custom retrieval-augmented generation (RAG) pipelines  
- ğŸ§© Model interpretability and optimization techniques  

---

## ğŸ“« Connect With Me
<p align="center">
  <a href="mailto:pandya.hariom@gmail.com"><img src="https://img.shields.io/badge/Gmail-D14836?style=for-the-badge&logo=gmail&logoColor=white" /></a>
  <a href="https://www.linkedin.com/in/pandya-hariom/en"><img src="https://img.shields.io/badge/LinkedIn-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white" /></a>
  <a href="https://huggingface.co/hapandya"><img src="https://img.shields.io/badge/HuggingFace-FFD21E?style=for-the-badge&logo=huggingface&logoColor=black" /></a>
  <a href="https://scholar.google.co.in/citations?user=cXw0BegAAAAJ"><img src="https://img.shields.io/badge/Google_Scholar-4285F4?style=for-the-badge&logo=googlescholar&logoColor=white" /></a>
</p>

---

â­ *â€œBridging academic AI research with real-world innovation through open collaboration.â€*
